{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pyodbc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDbAsDF(conn: pyodbc.Connection, sql:str):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    data = cursor.fetchall()\n",
    "\n",
    "    columns = [column[0] for column in cursor.description]\n",
    "\n",
    "    formatted_data = {}\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        dataList = []\n",
    "        for j in data:\n",
    "            dataList.append(j[i])\n",
    "        formatted_data[columns[i]] = dataList\n",
    "\n",
    "    df = pd.DataFrame(data=formatted_data,columns=columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "salesConn = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=..\\..\\Data\\go_sales_schoon.accdb;')\n",
    "#WHY THE FUCK DOES ACCESS REQUIRE BRACKETS FOR MORE THAN ONE JOIN AND WHY DIT IT TAKE SO LONG FOR ME TO FIND THIS INFO REEEEEEEEEEEEEEEEEEEEE\n",
    "salesSQL = \"\"\"\n",
    "SELECT *\n",
    "FROM (((((returned_item\n",
    "INNER JOIN return_reason\n",
    "ON returned_item.RETURN_REASON_CODE = return_reason.RETURN_REASON_CODE)\n",
    "INNER JOIN order_details\n",
    "ON returned_item.ORDER_DETAIL_CODE = order_details.ORDER_DETAIL_CODE)\n",
    "INNER JOIN order_header\n",
    "ON order_header.ORDER_NUMBER = order_details.ORDER_NUMBER)\n",
    "INNER JOIN sales_sales_branch\n",
    "ON sales_sales_branch.SALES_BRANCH_CODE = order_header.SALES_BRANCH_CODE)\n",
    "INNER JOIN product\n",
    "ON product.PRODUCT_NUMBER = order_details.PRODUCT_NUMBER)\n",
    "INNER JOIN product_type\n",
    "ON product_type.PRODUCT_TYPE_CODE = product.PRODUCT_TYPE_CODE\n",
    "\"\"\"\n",
    "\n",
    "salesDF = getDbAsDF(salesConn, salesSQL)\n",
    "salesDF.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting suitable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workingDF = salesDF[[\"RETURN_QUANTITY\",\"RETURN_REASON_CODE\",\"ORDER_METHOD_CODE\",\"COUNTRY_CODE\",\"PRODUCT_TYPE_CODE\",\"SALES_BRANCH_CODE\",\"UNIT_PRICE\",\"PRODUCTION_COST\",\"PRODUCT_NUMBER\"]] # Don't know why this duplication happens \n",
    "workingDF = workingDF.T.drop_duplicates().T # But fix it here\n",
    "workingDF.dropna(inplace = True)\n",
    "print(workingDF.head())\n",
    "print(workingDF.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = workingDF.corr()\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='RETURN_REASON_CODE',\n",
    "                y='RETURN_QUANTITY', data=workingDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = workingDF.drop('RETURN_QUANTITY',axis= 1)\n",
    "y = workingDF['RETURN_QUANTITY']\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fitting the model\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "# making predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "\n",
    "print(\n",
    "  'mean_squared_error : ', mean_squared_error(y_test, predictions))\n",
    "print(\n",
    "  'mean_absolute_error : ', mean_absolute_error(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
